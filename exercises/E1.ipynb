{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## E1.0) Simulate Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- set random seed to 42\n",
    "- (1000,2) samples from $X \\sim \\mathcal{U}(0,1)$ , i.e. 1000 rows, 2 columns. \n",
    "- 1000 samples from $\\epsilon \\sim \\mathcal{N}(0,1)$\n",
    "- $y = 3x_1 + 5x_2 + 3 + \\epsilon$ , where $x_i$ is column $i$ of $X$\n",
    "\n",
    "Finally add a column of ones for the intercept to $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_dataset(samples, features, beta_values):\n",
    "    np.random.seed(42) # random seed for reproducability\n",
    "\n",
    "    # generating random X values based on samples and features\n",
    "    X = np.random.uniform(0, 1, (samples, features))\n",
    "\n",
    "    # column vector of ones for intercept\n",
    "    ones = np.ones(len(X))\n",
    "\n",
    "     # adding column of ones to feature matrix\n",
    "    X = np.c_[ones, X]\n",
    "\n",
    "    # generating random noise values\n",
    "    epsilon = np.random.normal(0, 1, samples)\n",
    "\n",
    "    # calculating y based on X dot multiplied with beta vector (note beta_0 multiplied by ones from the added column)\n",
    "    # adding epsilon for some random variance\n",
    "    y = np.dot(X, beta_values) + epsilon\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      "Shape: (1000, 3)\n",
      "[[1.         0.37454012 0.95071431]\n",
      " [1.         0.73199394 0.59865848]\n",
      " [1.         0.15601864 0.15599452]]\n",
      "\n",
      "y:\n",
      "Shape: (1000,)\n",
      "[7.9992093  7.36239389 4.02154963]\n"
     ]
    }
   ],
   "source": [
    "X, y = simulate_dataset(samples = 1000, features = 2, beta_values = [3, 3, 5])\n",
    "\n",
    "print(f\"X:\\nShape: {X.shape}\\n{X[:3]}\\n\")\n",
    "print(f\"y:\\nShape: {y.shape}\\n{y[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1], 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.87096518],\n",
       "       [ 0.38961418],\n",
       "       [-0.86829273]])"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randn(X.shape[1], 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Train | Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, train_fraction = 0.3, replace = False):\n",
    "    \n",
    "    # amount of indices to pick for training data\n",
    "    n = int(len(X) * train_fraction)\n",
    "\n",
    "    # n random indices between 0 and len(X) to use as training data\n",
    "    indices = np.random.choice(len(X), size = n, replace = replace)\n",
    "\n",
    "    # picking out indices as train, and all other indices as test\n",
    "    X_train = X[indices]\n",
    "    X_test = X[np.in1d(np.arange(len(X)), indices, invert = True)]\n",
    "\n",
    "    # NOTE: reshaping y-vectors to (..., 1) instead of (..., ) to be able to use in coming calculations\n",
    "    y_train = y[indices].reshape(-1, 1)\n",
    "    y_test = y[np.in1d(np.arange(len(y)), indices, invert = True)].reshape(-1, 1)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300, 3), (700, 3), (300, 1), (700, 1))"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# checking that dimensions look correct\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## E1.1 A) Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, learning_rate = 0.1, epochs = 500):\n",
    "    m = len(X)\n",
    "\n",
    "    # array of random values with equal amount of rows as X has columns (X.shape[1]), and 1 column\n",
    "    # for example X (1000, 3) -> theta (3, 1)\n",
    "    theta = np.random.randn(X.shape[1], 1)\n",
    "\n",
    "    lista = [[] for _ in range(len(X.T))]\n",
    "\n",
    "    # looping over epochs\n",
    "    for i in range(epochs):\n",
    "\n",
    "\n",
    "        # calculating gradient\n",
    "        gradient = 2 / m * X.T @ (X @ theta - y)\n",
    "\n",
    "        # updating theta based on learning rate and gradient\n",
    "        theta -= learning_rate * gradient\n",
    "\n",
    "        if i % 5 == 0:\n",
    "            for i, _ in enumerate(theta):\n",
    "                lista[i].append(theta[i])\n",
    "        \n",
    "    return theta, lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'value'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[335], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m500\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[39m# getting theta estimations based on training data\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m theta_hat, theta_list \u001b[39m=\u001b[39m gradient_descent(X_train, y_train, epochs \u001b[39m=\u001b[39;49m epochs)\n\u001b[0;32m      6\u001b[0m theta_hat\n",
      "Cell \u001b[1;32mIn[334], line 22\u001b[0m, in \u001b[0;36mgradient_descent\u001b[1;34m(X, y, learning_rate, epochs)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m \u001b[39m5\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     21\u001b[0m         \u001b[39mfor\u001b[39;00m i, _ \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(theta):\n\u001b[1;32m---> 22\u001b[0m             lista[i]\u001b[39m.\u001b[39mappend(theta[i]\u001b[39m.\u001b[39;49mvalue)\n\u001b[0;32m     24\u001b[0m \u001b[39mreturn\u001b[39;00m theta, lista\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'value'"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "\n",
    "# getting theta estimations based on training data\n",
    "theta_hat, theta_list = gradient_descent(X_train, y_train, epochs = epochs)\n",
    "\n",
    "theta_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, [array([3.13843901]), array([3.13843901]), array([3.13843901])])"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(theta_list[2]), theta_list[0][:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[324], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sns\u001b[39m.\u001b[39mlineplot(x \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m500\u001b[39m, \u001b[39m5\u001b[39m), y \u001b[39m=\u001b[39m theta_list[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mvalues)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "sns.lineplot(x = range(1, 500, 5), y = theta_list[0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((700, 1),\n",
       " array([[8.83920082],\n",
       "        [8.22565364],\n",
       "        [4.3592411 ]]))"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining prediction function\n",
    "predict = lambda x, theta: np.dot(x, theta)\n",
    "\n",
    "# predicting y-values based on X_test\n",
    "y_pred = predict(X_test, theta_hat)\n",
    "\n",
    "y_pred.shape, y_pred[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.7980729703106827\n",
      "MSE: 1.0154914305799596\n",
      "RMSE: 1.0077159473680863\n"
     ]
    }
   ],
   "source": [
    "# defining functions to calculate MAE, MSE, RMSE\n",
    "mean_absolute_error = lambda y_test, y_pred: np.sum(np.abs(y_test - y_pred)) / len(y_test)\n",
    "mean_squared_error = lambda y_test, y_pred: np.sum((y_test - y_pred) ** 2) / len(y_test)\n",
    "root_mean_squared_error = lambda y_test, y_pred: np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred)}\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred)}\")\n",
    "print(f\"RMSE: {root_mean_squared_error(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Machine-Learning-GjBaTmq0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "940a806c83d746f29468728088bb2fb4e64b6c5268b9352d3bc9450b64c9452f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
